## Union-Find算法
Union-Find，并查集算法，主要是解决图论中的 动态连通性 问题。

连通性问题介绍：动态连通性可以抽象成给一个图连线。比如一个有10个结点的图，互不相连，分别用0-9标记。
<br><img src=img/图.png><br>

使用Union-Find算法实现这几个API：
```java
class UF{
    //将p和q相连
    public void union(int p, int q);
    //判断p和q是否相连
    public boolean connected(int p, int q);
    //返回图中联通分量的个数
    public int count();
}
```
这里的连通是一种等价关系，具有如下三个性质：
1. 自反性：结点p和q是连通的。
2. 对称性：如果p和q连通，那么q和p也连通。
3. 传递性：如果p和q连通，q和r连通，那么p和r也连通。

例如上面的图，0-9任意两个结点都不连通，调用connected会返回false，连通分量为10个。
调用union(0, 1)，那么0和1被连通，连通分量变为9个。
在调用union(1,2)，此时0，1，2都被连通，调用connected(0,2)也会返回true，连通分量变为8个。

可以使用森林来表示图的连通性，用数组来具体实现这个森林。那么怎么用森林表示连通性呢，可以设定树的每个节点都有一个指针指向其父结点，如果是根节点的话，这个指针指向自己。

比如刚才那幅10个结点的图，一开始的时候没有相互连通，就是这样：
```java
class UF {
    // 记录连通分量
    private int count;
    // 节点 x 的节点是 parent[x]
    private int[] parent;

    /* 构造函数，n 为图的节点总数 */
    public UF(int n) {
        // 一开始互不连通
        this.count = n;
        // 父节点指针初始指向自己
        parent = new int[n];
        for (int i = 0; i < n; i++)
            parent[i] = i;
    }

    /* 其他函数 */
}
```
如果某两个结点被连通，则让其中的一个结点的根节点接到另一个结点的根节点上：
```java
public void union(int p, int q) {
    int rootP = find(p);
    int rootQ = find(q);
    if (rootP == rootQ)
        return;
    // 将两棵树合并为一棵
    parent[rootP] = rootQ;
    // parent[rootQ] = rootP 也一样
    count--; // 两个分量合二为一
}

/* 返回某个节点 x 的根节点 */
private int find(int x) {
    // 根节点的 parent[x] == x
    while (parent[x] != x)
        x = parent[x];
    return x;
}

/* 返回当前的连通分量个数 */
public int count() { 
    return count;
}
```
这样，如果p和q连通的话，他们一定有相同的根节点：
```java
public boolean connected(int p, int q) {
    int rootP = find(p);
    int rootQ = find(q);
    return rootP == rootQ;
}
```
可以看出，主要APIconnected和union中的复杂度都是find函数造成的，所以说复杂度和find一样。find的主要功能就是从某个结点向上遍历到树根，其时间复杂度就是树的高度。我们有可能习惯性的认为树的高度是logN，但是logN的高度只存在于平衡二叉树，对于一般的树可能出现极端不平衡的情况，使树退化为链表，树的最坏高度可能变成N。

所以上面的解法，find、union、connected的时间复杂度都是O(N)。图论解决的都是社交网络这样的规模巨大的问题，对于union和connected的调用非常频繁，每次调用需要线性时间完全不可忍受。问题的关键在于，如何避免树的不平衡。

### 平衡性优化
上面的方法union的过程就是简单粗暴的把p所在的树接到q所在的树的根节点下面，这就有可能出现头重脚轻的不平衡情况，比如下面这种局面：
<img src=img/UF1.png><br>

这样下去，树可能很不平衡。小一些的树接到大一些树下面，这样就能避免头重脚轻，更平衡一些，具体实现方案是额外使用一个size数组，记录每棵树包含的结点数，我们不妨成为重量：
```java
class UF {
    private int count;
    private int[] parent;
    // 新增一个数组记录树的“重量”
    private int[] size;

    public UF(int n) {
        this.count = n;
        parent = new int[n];
        // 最初每棵树只有一个节点
        // 重量应该初始化 1
        size = new int[n];
        for (int i = 0; i < n; i++) {
            parent[i] = i;
            size[i] = 1;
        }
    }

    //这样可以修改一下union方法：
    public void union(int p, int q) {
        int rootP = find(p);
        int rootQ = find(q);
        if (rootP == rootQ)
            return;

        // 小树接到大树下面，较平衡
        if (size[rootP] > size[rootQ]) {
            parent[rootQ] = rootP;
            size[rootP] += size[rootQ];
        } else {
            parent[rootP] = rootQ;
            size[rootQ] += size[rootP];
        }
        count--;
    }

}
```
### 路径压缩
压缩每棵树的高度，使树高度始终保持为常数：
<br><img src=img/UF2.png><br>

这样，find就能以O(1)的时间找到某一节点的根节点，相应的，connected和union复杂度都下降为O(1)。
```java
private int find(int x) {
    while (parent[x] != x) {
        // 进行路径压缩
        parent[x] = parent[parent[x]];
        x = parent[x];
    }
    return x;
}
```



## LRU算法
LRU，Leatest Revently Used，最近最少使用算法。删除时选择最近使用时间最久的进行删除。Lc146：设计一个LRU算法。首先要接收一个capacity参数作为缓存的最大容量，然后实现两个api，一个是put(key, val)方法存入键值对，另一个是get(key)方法获取key对应的val，如果key不存在则返回-1。这里的get和put方法都必须是O(1)的时间复杂度。LRU算法的工作示例：
```java
/* 缓存容量为 2 */
LRUCache cache = new LRUCache(2);
// 你可以把 cache 理解成一个队列
// 假设左边是队头，右边是队尾
// 最近使用的排在队头，久未使用的排在队尾
// 圆括号表示键值对 (key, val)

cache.put(1, 1);
// cache = [(1, 1)]

cache.put(2, 2);
// cache = [(2, 2), (1, 1)]

cache.get(1);       // 返回 1
// cache = [(1, 1), (2, 2)]
// 解释：因为最近访问了键 1，所以提前至队头
// 返回键 1 对应的值 1

cache.put(3, 3);
// cache = [(3, 3), (1, 1)]
// 解释：缓存容量已满，需要删除内容空出位置
// 优先删除久未使用的数据，也就是队尾的数据
// 然后把新的数据插入队头

cache.get(2);       // 返回 -1 (未找到)
// cache = [(3, 3), (1, 1)]
// 解释：cache 中不存在键为 2 的数据

cache.put(1, 4);    
// cache = [(1, 4), (3, 3)]
// 解释：键 1 已存在，把原始值 1 覆盖为 4
// 不要忘了也要将键值对提前到队头
```
通过上面的分析，可以得出cache这个数据结构必要的条件：
1. cache中的元素必须有序，以区分最近使用和久未使用的数据，容量满了之后要删除最久未使用的元素腾出位置;
2. 要在cache中快速找到某个key是否存在并得到对应的val，时间复杂度为O(1);
3. 每次访问cache中的某个key，需要将这个元素变为最近使用的，也就是说cache要支持在任意位置快速插入和删除元素。

哈希表查找快，但是数据无固定顺序；链表有序，插入删除快，但是查找慢，所以可以结合一下，形成一种新的数据结构：哈希链表LinkedHashMap。
<br><img src=img/LinkedHashMap.webp><br>

借助哈希链表，分析一下上面的三个条件：
1. 如果每次默认从链表尾部添加元素，那么显然越靠近尾部的元素就是最近使用的，越靠近头部的元素就是最久未使用的。
2. 对于某一个key，我们可以通过哈希表快速定位到链表中的节点，从而取得对应的val。
3. 链表显然是支持在任意位置快速插入和删除的。只不过传统的链表是无法按照索引快速访问某一个位置的元素的，这里借助哈希表，可以通过key快速映射到任意一个链表节点，然后进行插入和删除。

### 代码实现
不使用LinkedHashMap，实现一遍LRU算法：
```java
class Node{
    public int key, val;
    public Node next, prev;
    public Node(int key, int val){
        this.key = key;
        this.val = val;
    }
}

class DoubleList{
    //虚头尾节点
    private Node head,tail;
    //链表元素数
    private int size;

    public DoubleList(){
        head = new Node(0, 0);
        tail = new Node(0, 0);
        head.next = tail;
        tail.prev = head;
        size = 0;
    }

    //在链表尾部添加节点node 时间复杂度O(1)
    public void addLast(Node node){
        node.prev = tail.prev;
        node.next = tail;
        tail.prev.next = node;
        tail.prev = node;
        size++;
    }

    //删除链表中的node节点（节点一定存在）
    //由于使用的是双链表并且给定了目标节点，所以时间复杂度O(1)
    public void remove(Node node){
        node.prev.next = node.next;
        node.next.prev = node.prev;
        size--;
    }

    //删除链表中的第一个节点，并返回该节点，时间O(1)
    public Node removeFirst(){
        if(head.next == null)
            return null;
        Node node = head.next;
        head.next = node.next;
        node.next.prev = head;
        size--;
        return node;
    }
    
    //返回链表长度，时间O(1)
    public int size(){
        return size;
    }

}
```
由于删除操作不仅仅需要得到该节点本身，还需要知道该节点的前驱，而双向链表才支持直接查找前驱，保证操作的时间复杂度为O(1)。有了双向链表的实现，可以实现LRU算法：
```java
class LRUCache{
    private HashMap<Integer, Node> map;
    private DoubleList cache;
    private int cap;

    public LRUCache(int capcity){
        cap = capacity;
        map = new HashMap<>();
        cache = new DoubleList();
    }

}
```
由于要同时维护一个双链表和一个哈希表，所以很容易漏掉操作，为了避免这种问题，可以在这两种数据结构之上提供一层抽象API，尽量让LRU的主方法get和put避免直接操作map和cache的细节。先实现下面几个方法：
```java
// 将key提升为最近使用的
private void markRecently(int key){
    Node node = map.get(key);
    cache.remove(node);
    cache.addLast(node);
}

//添加最近使用的元素
private void addRecently(int key, int val){
    Node node = new Node(key, val);
    cache.addLast(node);
    map.put(key, node);
}

//删除某一个key
private void deleteKey(int key){
    Node node = map.get(key);
    cache.remove(node);
    map.remove(key);
}

//删除最久未使用的元素
private void removeLeastRecently()[
    //链表头部第一个节点就是最久未使用的
    Node delNode = cache.removeFirst();
    //还需要从map中删除key
    map.remove(delNode.key);
]
```
由于当容量满了之后删除最后一个结点时，同时删除map中的key需要用到key，所以双边链表中也应该存储一个key值，而不能只存val。接下来就可以实现get和put方法了：
```java
public int get(int key){
    if(!map.containsKey(key)){
        return -1;
    }
    //把该数据提升为最近使用的
    markRecently(key);
    return map.get(key).val;
}

public void put(int key, int val){
    //如果key已经存在，就删除原来的值插入新值
    if(map.containsKey(key)){
        deleteKey(key);
        addRecently(key, val);
        return;
    }

    //如果容量已满，删除最久未使用的key再插入
    if(cap == cache.size()){
        removeLeastRecently();
    }
    addRecentLy(key, val);
}

```



## LFU算法
Least Frequently Used，最不经常使用算法，淘汰最近一段时间内访问频次最低的元素。如果访问频次最低的数据有多条，需要淘汰最旧的数据。Lc460
```java
class LFUCache {
    // 构造容量为 capacity 的缓存
    public LFUCache(int capacity) {}
    // 在缓存中查询 key
    public int get(int key) {}
    // 将 key 和 val 存入缓存
    public void put(int key, int val) {}
}
```
get(key)方法会去缓存中查询key，如果key存在，返回val，否则返回-1。

put(key, value)方法插入或者修改缓存，如果已经存在，将它对应的值修改为val，如果key不存在，则插入键值对(key,val)。

当容量达到capacity时，则应该在插入新的键值对之前，删除使用频次freq最低的键值对，如果freq最低的键值有多个，则删除其中最旧的那个。

### 思路分析
算法的执行过程分析：
1. 调用get方法时，返回key对应的val。
2. 只要用get或者put方法访问一次某个key，该key的freq就要加一。
3. 如果容量满了的时候进行插入，则需要将freq最小的key删除，如果最小的freq对应多个key，则删除最旧的那个。

设计数据结构：
1. 使用一个HashMap存储key到val的映射，就可以快速计算get(key)。``HashMap<Integer, Integer> keyToVal;
``
2. 使用一个HashMap存储key到freq的映射，就可以快速操作key对应的freq。``HashMap<Integer, Integer> keyToFreq;
``
3. 这个需求是LFU算法的核心：
    1. 首先肯定是需要freq到key的映射，用来找到freq最小的key。
    2. 将freq最小的key删除，就得快速得到当前所有key最小的freq是多少，如果要时间复杂度为O(1)的话，肯定不能遍历查找，可以使用一个变量minFreq来记录当前最小的freq。
    3. 可能存在多个key拥有相同的freq，所以freq对key是一对多的关系，即一个freq对应一个key的列表。
    4. freq对应key的列表是有时序的，便于快速查找并删除最旧的key。
    5. 能快速删除key列表中的任何一个key，因为如果频次为freq的某个key被访问，那么它的频次就会变成freq+1，就应该从freq对应的key列表中删除，加到freq+1对应的列表中

第三点需求的数据结构实现：
```java
HashMap<Integer, LinkedHashSet<Integer>> freqToKeys;
```
LinkedHashSet，为链表和哈希结合的结合体，既可以在O(1)时间内访问或删除其中的元素，又可以保持插入的时序。

综上，可以写出LFU的基本数据结构：
```java
class LFUCache {
    // key 到 val 的映射，我们后文称为 KV 表
    HashMap<Integer, Integer> keyToVal;
    // key 到 freq 的映射，我们后文称为 KF 表
    HashMap<Integer, Integer> keyToFreq;
    // freq 到 key 列表的映射，我们后文称为 FK 表
    HashMap<Integer, LinkedHashSet<Integer>> freqToKeys;
    // 记录最小的频次
    int minFreq;
    // 记录 LFU 缓存的最大容量
    int cap;

    public LFUCache(int capacity) {
        keyToVal = new HashMap<>();
        keyToFreq = new HashMap<>();
        freqToKeys = new HashMap<>();
        this.cap = capacity;
        this.minFreq = 0;
    }

    public int get(int key) {}

    public void put(int key, int val) {}

}
```
实现LFU算法需要维护三个映射，非常容易出错，对于这种情况，可以使用下面的技巧：
1. 不要企图上来就实现算法的所有细节，应该自顶向下，逐步求精，先写清楚主函数的逻辑框架，然后再一步步实现细节。
2. 搞清楚映射关系，如果我们更新了某个key对应的freq，那么就要同步修改KF表和FK表，这样才不会出问题。
3. 画图，逻辑比较复杂可以先画出流程图，然后根据图来写代码。

### 代码实现
先写出函数框架：
```java
public int get(int key){
    if(!keyToVal.containsKey(key)){
        return -1;
    }
    //增加key对应的freq
    increaseFreq(key);
    return keyToVal.get(key);
}

public void put(int key, int val){
    //如果key已经存在，修改对应的val即可
    if(keyToVal.containsKey(key)){
        keyToVal.put(key, val);
        increaseFreq(key);
        return;
    }

    //key不存在需要插入
    //容量已满淘汰一个freq最小的key
    if(this.cap <= keyToVal.size()){
        removeMinFreqKey();
    }

    //插入key和val，对应的freq为1
    //插入KV表
    keyToVal.put(key, val);
    //插入KF表
    keyToFreq.put(key, 1);
    //插入FK表
    freqToKeys.putIfAbsent(1, new LinkedList<>());
    freqToKeys.get(1).add(key);
    //插入新key后最小的freq肯定是1
    this.minFreq = 1;
}
```
### LFU核心逻辑
increaseFreq和removeMinFreqKey方法是 LFU 算法的核心
```java
private void removeMinFreqKey(){
    //找出freq最小的列表
    LinkedHashSet<Integer> keyList = freqToKeys.get(this.minFreq);
    //最先插入的那个就是应该被淘汰的key
    int deletedKey = keyList.iterator().next();
    
    //更新FK表
    keyList.remove(deletedKey);
    if(keyList.isEmpty()){
        //如果keyList为空，删除这个freq
        freqToKeys.remove(this.minFreq);
        //删除freq之后，理论上是需要更新minFreq，但是实际上调用removeMinFreqKey方法是在插入时，所以之后肯定会插入新元素，把minFreq更新为最小值1.
    }
    //更新KV表
    keyToVal.remove(deletedKey);
    //更新KF表
    keyToFreq.remove(deletedKey);
}

private void increaseFreq(int key){
    int freq = keyToFreq.get(key);
    //更新KF表
    keyToFreq.put(key, freq+1);
    //更新FK表
    //把key从freq对应的列表中删除
    freqToKeys.get(freq).remove(key);
    //把key加入freq+1对应的列表中
    freqTokeys.putIfAbsent(freq+1, new LinkedHashSet<>());
    freqToKeys.get(freq+1).add(Key);
    //如果freq对应的列表空了，移除这个freq
    if(freqToKeys.get(freq).isEmpty()){
        freqToKeys.remove(freq);
        //如果freq刚好是miFreq，更新minFreq
        if(freq == this.minFreq){
            this.minFreq++;
        }
    }
}
```


## 数据流的中位数
Lc 295。解法思路：
* 思路1：维护一个容器，取中位数时进行排序，输出中间值。
    * 时间复杂度：插入O(1)+查询O(nlogn) = O(nlogn).
    * 插入元素O(1)
    * 找到中间值：O(nlogn)
* 思路2：维护一个有序队列，每次插入维护队列的有序性。
    * 时间复杂度：查找位置O(logn)+插入元素O(n)
    * 二分查找花费O(logn)级别找到位置
    * 插入元素时间复杂度O(n)，因为必须移动容器为新元素腾出空间。
* 思路3：两个堆，利用堆的特性：添加元素需要O(logn)级别的时间复杂度，并且可以直接访问数组中的最大/最小元素。那么我们可以维护两个堆：
    * 用于存放输入数字中较小一半的最大堆small。
    * 存放输入数字中较大一半的最小堆large。
    * 最大堆中的堆顶是较小一半的最大值，最小堆中的堆顶是较大一半的最小值，可以根据两个值来得出这些元素的中位数。

问题在于，如何维护large堆的整体元素和small元素的个数之差不超过1，以及large堆的元素大于等于small堆的元素（或者说large堆的堆顶大于等于small堆的堆顶元素）。

插入元素时，不能直接选择插入到某一个队列中，这样可能会导致不符合两个堆的定义。简单来说，如果要向large中添加元素，不能直接在large堆中添加，而是先添加到small堆中，再把small堆中的最大值即堆顶元素插入到large堆里。

## 设计Twitter：合并 k 个有序链表和面向对象设计
Lc355。设计用户和用户的关联，用户和推文的关联。核心的功能点是getNewsFeed，因为要求返回的结果必须在时间上有序，而用户的关注列表又是动态变化的。设计方案：把一个用户的推文存储在一个链表里，每个链表节点存储文章id和一个时间戳time，而这个节点是按time有序的，如果某个用户关注了k个用户，我们就可以用合并k个有序链表的方式来合并出有序的推文链表。

此题中还需要用到面向对象的思想来设计用户和推文类

## 单调栈
主要用来解决 Next Great Number 一类算法问题
1. Lc 496
2. Lc 739
3. Lc 503

